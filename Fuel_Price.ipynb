{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e1434d-75da-41ec-87f8-e072de0d0e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Build route universe (OpenFlights)...\n",
      " - Found 148 India airports and 955 intra-India routes (raw).\n",
      " - Unique intra-India route pairs after dedupe: 343\n",
      "\n",
      "STEP 2: Fetching India ATF time series (data.gov.in -> IOCL -> FRED fallback)...\n",
      "  - Trying data.gov.in resource page for CSV link...\n",
      "  - No usable CSV found on data.gov.in page.\n",
      "  - Trying IOCL pages for ATF price tables...\n",
      "    trying https://iocl.com/aviation-fuel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anklesh\\AppData\\Local\\Temp\\ipykernel_25108\\3829118997.py:201: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(r.text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    trying https://iocl.com/atf-domestic-airlines\n",
      "    trying https://iocl.com/prices-of-petroleum-products\n",
      "  - No usable table found on IOCL pages.\n",
      "  - Falling back to FRED jet fuel series (converted to INR).\n",
      "  - FRED fallback loaded.\n",
      "\n",
      "Normalizing ATF time series...\n",
      "  - ATF time series saved to outputs/atf_time_series.csv (rows: 1245)\n",
      "  - ATF time series plot saved to outputs/atf_timeseries.png\n",
      "\n",
      "STEP 3: Building route-level economics using latest ATF price...\n",
      "  - Latest ATF (INR/L) used: 41.35 INR/L\n",
      "  - Saved base P&L to outputs\\route_economics_base.csv\n",
      "\n",
      "STEP 4: Simulating fuel shock and Option B (UDAN support) scenario...\n",
      "  - Saved post-shock + UDAN scenario to outputs\\route_economics_postshock_udan.csv\n",
      "\n",
      "STEP 5: KPI summary and UDAN impact...\n",
      "  - Summary saved to outputs/summary_metrics_udan.txt\n",
      "\n",
      "STEP 6: Producing charts (ATF series, margins distribution, UDAN impact)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anklesh\\AppData\\Local\\Temp\\ipykernel_25108\\3829118997.py:428: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  f\"Analysis timestamp (UTC): {datetime.utcnow().isoformat()}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Charts saved: outputs/atf_timeseries.png, outputs/margins_udan_comparison.png\n",
      "  - routes saved by UDAN (top20) saved to outputs/routes_saved_by_udan_top20.csv\n",
      "  - PPTX generated: outputs/fuel_shock_udan_deck.pptx\n",
      "\n",
      "DONE. Outputs are in the 'outputs' folder:\n",
      " - outputs/atf_time_series.csv\n",
      " - outputs/atf_timeseries.png\n",
      " - outputs/route_economics_base.csv\n",
      " - outputs/route_economics_postshock_udan.csv\n",
      " - outputs/routes_saved_by_udan_top20.csv\n",
      " - outputs/summary_metrics_udan.txt\n",
      " - outputs/margins_udan_comparison.png\n",
      " - optional: outputs/fuel_shock_udan_deck.pptx (if python-pptx installed)\n"
     ]
    }
   ],
   "source": [
    "# fuel_shock_atf_realtime.py\n",
    "# Purpose: Fetch real ATF time series (India) and run the fuel-shock + UDAN scenario analysis\n",
    "# Uses OpenFlights for route universe, tries data.gov.in and IOCL for ATF series, falls back to FRED.\n",
    "# Produces CSVs, charts, and an executive summary.\n",
    "# Problem statement (IIT Guwahati Winter Consulting, Case 1) used to structure deliverables. :contentReference[oaicite:1]{index=1}\n",
    "\n",
    "import os\n",
    "import io\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pandas_datareader.data import DataReader\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ---------------------------\n",
    "# OUTPUT\n",
    "# ---------------------------\n",
    "OUTDIR = \"outputs\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# ASSUMPTIONS (editable)\n",
    "# ---------------------------\n",
    "ASSUMPTIONS = {\n",
    "    # fleet / pax\n",
    "    \"avg_seats\": 78,\n",
    "    \"default_load_factor\": 0.72,\n",
    "    \"avg_fare_inr\": 3000.0,\n",
    "    \"avg_ancillary_inr\": 400.0,\n",
    "    # costs\n",
    "    \"fixed_cost_per_flight_inr\": 250000.0,\n",
    "    \"liters_per_km_per_seat\": 0.03,\n",
    "    # currency\n",
    "    \"usd_to_inr\": 82.0,\n",
    "    # fuel shock scenario (if you want to shock relative to latest)\n",
    "    \"fuel_shock_pct\": 0.25,\n",
    "    # pricing scenario (not primary here, we focus on Option B)\n",
    "    \"fare_increase_pct\": 0.06,\n",
    "    \"price_elasticity\": -1.0,\n",
    "    # UDAN/support scenario (Option B)\n",
    "    \"udan_monthly_support_inr\": 50000.0,\n",
    "    \"flights_per_month_default\": 60,\n",
    "    # OpenFlights source (route universe)\n",
    "    \"openflights_airports_url\": \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\",\n",
    "    \"openflights_routes_url\": \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat\",\n",
    "    # data.gov.in ATF resource (we'll try to scrape CSV link here)\n",
    "    \"data_gov_atf_resource_url\": \"https://www.data.gov.in/resource/effective-date-wise-prices-aviation-turbine-fuel-atf-indian-oil-corporation-limited-iocl\",\n",
    "    # IOCL pages to try if data.gov.in fails\n",
    "    \"iocl_atf_pages\": [\n",
    "        \"https://iocl.com/aviation-fuel\",\n",
    "        \"https://iocl.com/atf-domestic-airlines\",\n",
    "        \"https://iocl.com/prices-of-petroleum-products\"\n",
    "    ],\n",
    "    # FRED fallback series (US Gulf Coast jet fuel) - used only if India sources fail\n",
    "    \"fred_series\": \"DJFUELUSGULF\"\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# UTILITIES\n",
    "# ---------------------------\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2.0)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2.0)**2\n",
    "    return 2 * R * math.asin(math.sqrt(a))\n",
    "\n",
    "def safe_get(url, timeout=20):\n",
    "    try:\n",
    "        r = requests.get(url, timeout=timeout)\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "    except Exception as e:\n",
    "        print(f\"  [WARN] Failed to GET {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 1: Build route universe with OpenFlights\n",
    "# ---------------------------\n",
    "print(\"STEP 1: Build route universe (OpenFlights)...\")\n",
    "airports_txt = requests.get(ASSUMPTIONS[\"openflights_airports_url\"]).text\n",
    "routes_txt = requests.get(ASSUMPTIONS[\"openflights_routes_url\"]).text\n",
    "\n",
    "airports_cols = [\"id\",\"name\",\"city\",\"country\",\"iata\",\"icao\",\"lat\",\"lon\",\"alt\",\"tz\",\"dst\",\"tzdb\",\"type\",\"src\"]\n",
    "routes_cols = [\"airline\",\"airline_id\",\"src\",\"src_id\",\"dst\",\"dst_id\",\"codeshare\",\"stops\",\"equip\"]\n",
    "\n",
    "airports = pd.read_csv(io.StringIO(airports_txt), header=None, names=airports_cols, dtype=str, keep_default_na=False)\n",
    "routes = pd.read_csv(io.StringIO(routes_txt), header=None, names=routes_cols, dtype=str, keep_default_na=False)\n",
    "\n",
    "# sanitize numeric fields\n",
    "airports[\"lat\"] = pd.to_numeric(airports[\"lat\"], errors=\"coerce\")\n",
    "airports[\"lon\"] = pd.to_numeric(airports[\"lon\"], errors=\"coerce\")\n",
    "airports[\"id\"] = pd.to_numeric(airports[\"id\"], errors=\"coerce\")\n",
    "routes[\"src_id\"] = pd.to_numeric(routes[\"src_id\"], errors=\"coerce\")\n",
    "routes[\"dst_id\"] = pd.to_numeric(routes[\"dst_id\"], errors=\"coerce\")\n",
    "\n",
    "india_airports = airports[airports[\"country\"].str.strip().str.lower() == \"india\"].copy()\n",
    "india_airport_ids = set(india_airports[\"id\"].dropna().astype(int).tolist())\n",
    "\n",
    "routes[\"in_india\"] = routes.apply(\n",
    "    lambda r: (pd.notna(r[\"src_id\"]) and pd.notna(r[\"dst_id\"]) and int(r[\"src_id\"]) in india_airport_ids and int(r[\"dst_id\"]) in india_airport_ids),\n",
    "    axis=1\n",
    ")\n",
    "india_routes = routes[routes[\"in_india\"]].copy().reset_index(drop=True)\n",
    "print(f\" - Found {len(india_airports)} India airports and {len(india_routes)} intra-India routes (raw).\")\n",
    "\n",
    "id2airport = india_airports.set_index(\"id\")[[\"iata\",\"city\",\"lat\",\"lon\",\"name\"]]\n",
    "enriched = []\n",
    "for _, r in india_routes.iterrows():\n",
    "    try:\n",
    "        s = id2airport.loc[int(r[\"src_id\"])]\n",
    "        d = id2airport.loc[int(r[\"dst_id\"])]\n",
    "    except Exception:\n",
    "        continue\n",
    "    if pd.isna(s[\"lat\"]) or pd.isna(d[\"lat\"]):\n",
    "        continue\n",
    "    dist = haversine_km(float(s[\"lat\"]), float(s[\"lon\"]), float(d[\"lat\"]), float(d[\"lon\"]))\n",
    "    enriched.append({\n",
    "        \"src_iata\": s[\"iata\"],\n",
    "        \"dst_iata\": d[\"iata\"],\n",
    "        \"src_city\": s[\"city\"],\n",
    "        \"dst_city\": d[\"city\"],\n",
    "        \"distance_km\": round(dist,1)\n",
    "    })\n",
    "\n",
    "routes_df = pd.DataFrame(enriched).drop_duplicates().reset_index(drop=True)\n",
    "if routes_df.empty:\n",
    "    # fallback small synthetic sample\n",
    "    routes_df = pd.DataFrame([\n",
    "        {\"src_iata\":\"GAU\",\"dst_iata\":\"IMF\",\"src_city\":\"Guwahati\",\"dst_city\":\"Imphal\",\"distance_km\":350},\n",
    "        {\"src_iata\":\"DEL\",\"dst_iata\":\"JAI\",\"src_city\":\"Delhi\",\"dst_city\":\"Jaipur\",\"distance_km\":260},\n",
    "        {\"src_iata\":\"PAT\",\"dst_iata\":\"CCU\",\"src_city\":\"Patna\",\"dst_city\":\"Kolkata\",\"distance_km\":240}\n",
    "    ])\n",
    "    print(\" - Warning: route universe empty; using small synthetic sample (demo).\")\n",
    "else:\n",
    "    print(f\" - Unique intra-India route pairs after dedupe: {len(routes_df)}\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2: Try fetching real ATF time series (India)\n",
    "# Strategy:\n",
    "#  1) Try to find a CSV on the data.gov.in resource page\n",
    "#  2) If not found, scrape IOCL pages for ATF price tables\n",
    "#  3) Fallback: use FRED jet fuel series converted to INR\n",
    "# ---------------------------\n",
    "print(\"\\nSTEP 2: Fetching India ATF time series (data.gov.in -> IOCL -> FRED fallback)...\")\n",
    "\n",
    "def try_data_gov_csv(resource_page_url):\n",
    "    print(\"  - Trying data.gov.in resource page for CSV link...\")\n",
    "    r = safe_get(resource_page_url)\n",
    "    if r is None:\n",
    "        return None\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    # find links that look like CSV or download endpoints\n",
    "    candidates = []\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        if href.lower().endswith(\".csv\"):\n",
    "            candidates.append(href)\n",
    "        # sometimes 'download' links are present with /download or /download? etc\n",
    "        if \"download\" in href.lower() and (href.lower().endswith(\".csv\") or \"format=csv\" in href.lower()):\n",
    "            candidates.append(href)\n",
    "    # normalize and attempt download\n",
    "    for href in candidates:\n",
    "        if href.startswith(\"//\"):\n",
    "            href = \"https:\" + href\n",
    "        if href.startswith(\"/\"):\n",
    "            href = \"https://data.gov.in\" + href\n",
    "        print(f\"    trying candidate CSV: {href}\")\n",
    "        rr = safe_get(href)\n",
    "        if rr is None:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.read_csv(io.StringIO(rr.text))\n",
    "            print(\"    -> Successfully loaded CSV from data.gov.in resource.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            # Try saving to bytes and read by pandas\n",
    "            try:\n",
    "                df = pd.read_csv(io.BytesIO(rr.content))\n",
    "                print(\"    -> Successfully loaded CSV (bytes) from data.gov.in resource.\")\n",
    "                return df\n",
    "            except Exception:\n",
    "                print(f\"    -> Failed to parse candidate {href}: {e}\")\n",
    "                continue\n",
    "    print(\"  - No usable CSV found on data.gov.in page.\")\n",
    "    return None\n",
    "\n",
    "def try_iocl_scrape(pages):\n",
    "    print(\"  - Trying IOCL pages for ATF price tables...\")\n",
    "    for url in pages:\n",
    "        print(f\"    trying {url}\")\n",
    "        r = safe_get(url)\n",
    "        if r is None:\n",
    "            continue\n",
    "        try:\n",
    "            tables = pd.read_html(r.text)\n",
    "        except Exception as e:\n",
    "            # sometimes HTML parsing fails; try BeautifulSoup to find table-like content\n",
    "            tables = []\n",
    "        for t in tables:\n",
    "            # look for columns or values that indicate ATF or 'ATF' string\n",
    "            text = \" \".join(t.columns.astype(str)).lower()\n",
    "            if any(\"atf\" in c.lower() or \"turbine\" in c.lower() or \"aviation\" in c.lower() for c in t.columns.astype(str)) or t.shape[1] <= 3:\n",
    "                # attempt to coerce to time series: find date-like column and price-like column\n",
    "                # heuristics: columns with 'date', 'effective', 'month' OR numeric series with 'price'\n",
    "                df = t.copy()\n",
    "                # simple cleaning: try to melt if first col are dates\n",
    "                # return df for manual inspection - we'll let caller process\n",
    "                print(f\"    -> Found a candidate table on {url} with shape {df.shape}\")\n",
    "                return df\n",
    "    print(\"  - No usable table found on IOCL pages.\")\n",
    "    return None\n",
    "\n",
    "atf_df = None\n",
    "# 1) data.gov.in attempt\n",
    "atf_df = try_data_gov_csv(ASSUMPTIONS[\"data_gov_atf_resource_url\"])\n",
    "\n",
    "# 2) IOCL attempt\n",
    "if atf_df is None:\n",
    "    iocl_candidate = try_iocl_scrape(ASSUMPTIONS[\"iocl_atf_pages\"])\n",
    "    if iocl_candidate is not None:\n",
    "        # heuristic: try to reshape candidate into time series if possible\n",
    "        atf_df = iocl_candidate\n",
    "\n",
    "# 3) fallback to FRED jet fuel converted to INR\n",
    "if atf_df is None:\n",
    "    print(\"  - Falling back to FRED jet fuel series (converted to INR).\")\n",
    "    try:\n",
    "        end = datetime.today()\n",
    "        start = datetime(end.year - 5, end.month, end.day)\n",
    "        fred_series = DataReader(ASSUMPTIONS[\"fred_series\"], \"fred\", start, end)\n",
    "        fred_series = fred_series.dropna().reset_index()\n",
    "        fred_series.columns = [\"date\", \"usd_per_gallon\"]\n",
    "        fred_series[\"usd_per_liter\"] = fred_series[\"usd_per_gallon\"] / 3.78541\n",
    "        fred_series[\"inr_per_liter\"] = fred_series[\"usd_per_liter\"] * ASSUMPTIONS[\"usd_to_inr\"]\n",
    "        atf_df = fred_series[[\"date\",\"inr_per_liter\"]].rename(columns={\"inr_per_liter\":\"price_inr_per_liter\",\"date\":\"date\"})\n",
    "        print(\"  - FRED fallback loaded.\")\n",
    "    except Exception as e:\n",
    "        print(\"  - FRED fetch failed:\", e)\n",
    "        # final fallback: synthetic price series\n",
    "        dates = pd.date_range(end=datetime.today(), periods=24, freq='M')\n",
    "        prices = np.linspace(110, 160, len(dates))  # INR/L arbitrary\n",
    "        atf_df = pd.DataFrame({\"date\":dates, \"price_inr_per_liter\":prices})\n",
    "        print(\"  - Using synthetic ATF series (last-resort).\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2b: Normalize ATF DataFrame into a time series: columns ['date','price_inr_per_liter']\n",
    "# ---------------------------\n",
    "print(\"\\nNormalizing ATF time series...\")\n",
    "\n",
    "def normalize_atf(df):\n",
    "    # Attempt various heuristics depending on the source structure\n",
    "    df = df.copy()\n",
    "    # If column names contain 'price' or 'inr' or '₹' or 'Rs', try to find price col\n",
    "    text_cols = [c.lower() for c in df.columns.astype(str)]\n",
    "    # find date col\n",
    "    date_col = None\n",
    "    price_col = None\n",
    "    for c in df.columns:\n",
    "        lc = str(c).lower()\n",
    "        if any(k in lc for k in [\"date\",\"effective\",\"month\",\"period\"]):\n",
    "            date_col = c\n",
    "        if any(k in lc for k in [\"price\",\"rate\",\"inr\",\"₹\",\"rs\",\"amount\",\"price_inr\",\"price_kl\"]):\n",
    "            price_col = c\n",
    "    # If not found, try positional heuristics\n",
    "    if date_col is None:\n",
    "        # try first column if it looks like dates\n",
    "        try:\n",
    "            tmp = pd.to_datetime(df.iloc[:,0], errors='coerce')\n",
    "            if tmp.notna().sum() > 0:\n",
    "                date_col = df.columns[0]\n",
    "        except Exception:\n",
    "            pass\n",
    "    if price_col is None:\n",
    "        # try numeric columns that have biggest variance\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if numeric_cols:\n",
    "            # pick the numeric column with the largest mean (likely price in INR per KL if huge)\n",
    "            price_col = numeric_cols[0]\n",
    "    # If still not found, attempt to melt table: some tables have months as columns\n",
    "    if date_col is None or price_col is None:\n",
    "        # try to find date in index or column headers (like month columns)\n",
    "        # Try simple wide->long transformation if first col is month names and remaining are values\n",
    "        try:\n",
    "            # assume first col is 'month' or index-like\n",
    "            if df.shape[1] >= 2:\n",
    "                # convert header to string and check if any header contains year-like text\n",
    "                header_text = \" \".join([str(c) for c in df.columns])\n",
    "                # try melt\n",
    "                melted = df.melt(id_vars=[df.columns[0]], var_name=\"period\", value_name=\"value\")\n",
    "                # try parse date from 'period' or first col\n",
    "                for col in [melted.columns[0], \"period\"]:\n",
    "                    try:\n",
    "                        candidate = pd.to_datetime(melted[col], errors='coerce')\n",
    "                        if candidate.notna().sum() > 0:\n",
    "                            melted[\"date\"] = candidate\n",
    "                            melted[\"price\"] = pd.to_numeric(melted[\"value\"], errors='coerce')\n",
    "                            result = melted[[\"date\",\"price\"]].dropna().drop_duplicates()\n",
    "                            result = result.rename(columns={\"price\":\"price_inr_per_liter\"})\n",
    "                            return result\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        except Exception:\n",
    "            pass\n",
    "    # If we have both columns, coerce and return\n",
    "    if date_col is not None and price_col is not None:\n",
    "        try:\n",
    "            result = pd.DataFrame()\n",
    "            result[\"date\"] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "            # price could be per KL (e.g., INR per KL). We need to detect scale:\n",
    "            price_raw = pd.to_numeric(df[price_col].astype(str).str.replace(\",\",\"\").str.replace(\"₹\",\"\").str.replace(\"Rs\",\"\", case=False), errors='coerce')\n",
    "            # Heuristic: if mean price > 1000, likely INR per KL -> convert to per L\n",
    "            mean_price = price_raw.mean(skipna=True)\n",
    "            if mean_price is not None and mean_price > 1000:\n",
    "                # assume per kiloliter -> divide by 1000\n",
    "                result[\"price_inr_per_liter\"] = price_raw / 1000.0\n",
    "            else:\n",
    "                result[\"price_inr_per_liter\"] = price_raw\n",
    "            result = result.dropna(subset=[\"date\",\"price_inr_per_liter\"])\n",
    "            result = result.sort_values(\"date\").reset_index(drop=True)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(\"  [WARN] normalize_atf failed to coerce date/price columns:\", e)\n",
    "    # final fallback: try numeric column + index as dates\n",
    "    tmp = df.select_dtypes(include=[np.number])\n",
    "    if not tmp.empty:\n",
    "        result = pd.DataFrame()\n",
    "        # create fake monthly dates\n",
    "        n = tmp.shape[0]\n",
    "        result[\"date\"] = pd.date_range(end=datetime.today(), periods=n, freq=\"M\")\n",
    "        result[\"price_inr_per_liter\"] = tmp.iloc[:,0].astype(float).values\n",
    "        return result\n",
    "    # If nothing worked, return None\n",
    "    return None\n",
    "\n",
    "atf_ts = normalize_atf(atf_df)\n",
    "if atf_ts is None or atf_ts.empty:\n",
    "    print(\"  [ERROR] Could not normalize ATF series. Creating fallback synthetic series.\")\n",
    "    dates = pd.date_range(end=datetime.today(), periods=36, freq='M')\n",
    "    prices = np.linspace(100, 140, len(dates))\n",
    "    atf_ts = pd.DataFrame({\"date\":dates,\"price_inr_per_liter\":prices})\n",
    "\n",
    "# Save ATF time series\n",
    "atf_ts.to_csv(os.path.join(OUTDIR, \"atf_time_series.csv\"), index=False, encoding=\"utf-8\")\n",
    "print(f\"  - ATF time series saved to outputs/atf_time_series.csv (rows: {len(atf_ts)})\")\n",
    "\n",
    "# plot ATF series\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.plot(atf_ts[\"date\"], atf_ts[\"price_inr_per_liter\"], marker=\"o\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"ATF price (INR / L)\")\n",
    "plt.title(\"ATF price time series (India) — derived from data.gov.in / IOCL / fallback\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTDIR, \"atf_timeseries.png\"))\n",
    "plt.close()\n",
    "print(\"  - ATF time series plot saved to outputs/atf_timeseries.png\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3: Build route-level P&L using latest ATF price\n",
    "# ---------------------------\n",
    "print(\"\\nSTEP 3: Building route-level economics using latest ATF price...\")\n",
    "\n",
    "latest_price_inr_per_liter = float(atf_ts[\"price_inr_per_liter\"].dropna().iloc[-1])\n",
    "print(f\"  - Latest ATF (INR/L) used: {latest_price_inr_per_liter:.2f} INR/L\")\n",
    "\n",
    "df = routes_df.copy()\n",
    "df[\"seats\"] = ASSUMPTIONS[\"avg_seats\"]\n",
    "df[\"load_factor\"] = ASSUMPTIONS[\"default_load_factor\"]\n",
    "df[\"pax_onboard\"] = (df[\"seats\"] * df[\"load_factor\"]).round().astype(int)\n",
    "df[\"avg_fare_inr\"] = ASSUMPTIONS[\"avg_fare_inr\"]\n",
    "df[\"ancillary_inr\"] = ASSUMPTIONS[\"avg_ancillary_inr\"]\n",
    "df[\"revenue_per_flight\"] = df[\"pax_onboard\"] * (df[\"avg_fare_inr\"] + df[\"ancillary_inr\"])\n",
    "\n",
    "df[\"fuel_liters_per_flight\"] = (df[\"distance_km\"] * df[\"seats\"] * ASSUMPTIONS[\"liters_per_km_per_seat\"]).round(2)\n",
    "df[\"fuel_cost_inr\"] = df[\"fuel_liters_per_flight\"] * latest_price_inr_per_liter\n",
    "df[\"fixed_cost_inr\"] = ASSUMPTIONS[\"fixed_cost_per_flight_inr\"]\n",
    "df[\"total_cost_inr\"] = df[\"fuel_cost_inr\"] + df[\"fixed_cost_inr\"]\n",
    "df[\"margin_per_flight\"] = df[\"revenue_per_flight\"] - df[\"total_cost_inr\"]\n",
    "df[\"margin_per_pax\"] = df[\"margin_per_flight\"] / df[\"pax_onboard\"].replace(0, np.nan)\n",
    "\n",
    "base_csv = os.path.join(OUTDIR, \"route_economics_base.csv\")\n",
    "df.to_csv(base_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"  - Saved base P&L to {base_csv}\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4: Fuel shock + Option B (UDAN) scenario\n",
    "# ---------------------------\n",
    "print(\"\\nSTEP 4: Simulating fuel shock and Option B (UDAN support) scenario...\")\n",
    "\n",
    "# Fuel shock - relative to latest price\n",
    "df_shock = df.copy()\n",
    "df_shock[\"fuel_cost_inr_shock\"] = df_shock[\"fuel_liters_per_flight\"] * (latest_price_inr_per_liter * (1.0 + ASSUMPTIONS[\"fuel_shock_pct\"]))\n",
    "df_shock[\"total_cost_inr_shock\"] = df_shock[\"fuel_cost_inr_shock\"] + df_shock[\"fixed_cost_inr\"]\n",
    "df_shock[\"margin_post_shock\"] = df_shock[\"revenue_per_flight\"] - df_shock[\"total_cost_inr_shock\"]\n",
    "\n",
    "# Option B: UDAN-like support (per-month support -> per-flight)\n",
    "support_month = ASSUMPTIONS[\"udan_monthly_support_inr\"]\n",
    "flights_per_month = ASSUMPTIONS[\"flights_per_month_default\"]\n",
    "support_per_flight = support_month / flights_per_month\n",
    "df_shock[\"margin_with_udan\"] = df_shock[\"margin_post_shock\"] + support_per_flight\n",
    "\n",
    "postshock_csv = os.path.join(OUTDIR, \"route_economics_postshock_udan.csv\")\n",
    "df_shock.to_csv(postshock_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"  - Saved post-shock + UDAN scenario to {postshock_csv}\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 5: KPI summary focused on Option B\n",
    "# ---------------------------\n",
    "print(\"\\nSTEP 5: KPI summary and UDAN impact...\")\n",
    "\n",
    "total_routes = len(df_shock)\n",
    "num_loss_base = (df_shock[\"margin_per_flight\"] < 0).sum()\n",
    "num_loss_post = (df_shock[\"margin_post_shock\"] < 0).sum()\n",
    "num_saved_by_udan = ((df_shock[\"margin_post_shock\"] < 0) & (df_shock[\"margin_with_udan\"] >= 0)).sum()\n",
    "num_still_negative_with_udan = (df_shock[\"margin_with_udan\"] < 0).sum()\n",
    "\n",
    "avg_margin_base = df_shock[\"margin_per_flight\"].mean()\n",
    "avg_margin_post = df_shock[\"margin_post_shock\"].mean()\n",
    "avg_margin_udan = df_shock[\"margin_with_udan\"].mean()\n",
    "\n",
    "summary = [\n",
    "    f\"Analysis timestamp (UTC): {datetime.utcnow().isoformat()}\",\n",
    "    \"Problem statement: IIT Guwahati Winter Consulting — Case 1. :contentReference[oaicite:2]{index=2}\",\n",
    "    \"\",\n",
    "    f\"Total routes analyzed: {total_routes}\",\n",
    "    f\"Routes loss-making (base): {num_loss_base}\",\n",
    "    f\"Routes loss-making (post fuel shock +{ASSUMPTIONS['fuel_shock_pct']*100:.0f}%): {num_loss_post}\",\n",
    "    f\"Routes that UDAN support (₹{support_month:.0f}/month) can save (flip to non-loss): {num_saved_by_udan}\",\n",
    "    f\"Routes still loss-making even with UDAN: {num_still_negative_with_udan}\",\n",
    "    \"\",\n",
    "    f\"Avg margin per flight (base): {avg_margin_base:,.0f} INR\",\n",
    "    f\"Avg margin per flight (post-shock): {avg_margin_post:,.0f} INR\",\n",
    "    f\"Avg margin per flight (with UDAN): {avg_margin_udan:,.0f} INR\",\n",
    "    \"\",\n",
    "    \"Key assumptions:\",\n",
    "    f\" - Latest ATF used: {latest_price_inr_per_liter:.2f} INR/L (derived from atf_time_series).\",\n",
    "    f\" - Seats/load factor: {ASSUMPTIONS['avg_seats']}/{ASSUMPTIONS['default_load_factor']}\",\n",
    "    f\" - Fixed cost per flight: ₹{ASSUMPTIONS['fixed_cost_per_flight_inr']:.0f}\",\n",
    "    f\" - UDAN monthly support assumed: ₹{support_month:.0f} (→ ₹{support_per_flight:.0f}/flight at {flights_per_month} flights/mo)\",\n",
    "    \"\",\n",
    "    \"Recommendation (from analysis):\",\n",
    "    \" - Use UDAN selectively to stabilize socially-important, high-volatility regional routes (Option B as buffer).\",\n",
    "    \" - Primary action remains network optimization & selective pricing on core routes (Option A) — UDAN supports downside protection.\",\n",
    "    \"\"\n",
    "]\n",
    "summary_txt = \"\\n\".join(summary)\n",
    "with open(os.path.join(OUTDIR, \"summary_metrics_udan.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary_txt)\n",
    "print(\"  - Summary saved to outputs/summary_metrics_udan.txt\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 6: Charts for slides (ATF series, margins, UDAN impact)\n",
    "# ---------------------------\n",
    "print(\"\\nSTEP 6: Producing charts (ATF series, margins distribution, UDAN impact)...\")\n",
    "\n",
    "# ATF time series plot already saved earlier as atf_timeseries.png; ensure exists by re-plotting simply\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.plot(atf_ts[\"date\"], atf_ts[\"price_inr_per_liter\"], marker=\"o\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"ATF price (INR / L)\")\n",
    "plt.title(\"ATF price (India) — time series (data.gov.in / IOCL / fallback)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTDIR, \"atf_timeseries.png\"))\n",
    "plt.close()\n",
    "\n",
    "# margins distribution base vs post-shock vs with UDAN\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(df_shock[\"margin_per_flight\"], bins=60, alpha=0.5, label=\"Base margin\")\n",
    "plt.hist(df_shock[\"margin_post_shock\"], bins=60, alpha=0.5, label=\"Post-shock margin\")\n",
    "plt.hist(df_shock[\"margin_with_udan\"], bins=60, alpha=0.5, label=\"With UDAN margin\")\n",
    "plt.axvline(0, color=\"k\", linewidth=0.8)\n",
    "plt.xlabel(\"Margin per flight (INR)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Margin distribution: base vs post-shock vs with UDAN\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTDIR, \"margins_udan_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# UDAN impact: how many routes recovered per city-pair (top)\n",
    "recovered = df_shock[(df_shock[\"margin_post_shock\"] < 0) & (df_shock[\"margin_with_udan\"] >= 0)].copy()\n",
    "recovered = recovered.assign(margin_deficit = df_shock[\"margin_post_shock\"] * -1).sort_values(\"margin_post_shock\")\n",
    "recovered.head(20).to_csv(os.path.join(OUTDIR, \"routes_saved_by_udan_top20.csv\"), index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"  - Charts saved: outputs/atf_timeseries.png, outputs/margins_udan_comparison.png\")\n",
    "print(\"  - routes saved by UDAN (top20) saved to outputs/routes_saved_by_udan_top20.csv\")\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 7: Quick PPTX (5 slides) including ATF timeseries & UDAN bullets (optional)\n",
    "# ---------------------------\n",
    "try:\n",
    "    from pptx import Presentation\n",
    "    from pptx.util import Inches\n",
    "    prs = Presentation()\n",
    "    # Title slide\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
    "    slide.shapes.title.text = \"Regional Airline — Fuel Shock & UDAN Analysis\"\n",
    "    slide.placeholders[1].text = \"Diagnosis, UDAN scenario & recommendation (IIT Guwahati Winter Consulting)\"\n",
    "    # Slide 1: ATF timeseries\n",
    "    s1 = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "    s1.shapes.title.text = \"Slide 1 — ATF time series (India)\"\n",
    "    s1.shapes.add_picture(os.path.join(OUTDIR, \"atf_timeseries.png\"), Inches(0.5), Inches(1.25), width=Inches(9))\n",
    "    # Slide 2: Margin impact\n",
    "    s2 = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "    s2.shapes.title.text = \"Slide 2 — Margin impact: base vs post-shock vs UDAN\"\n",
    "    s2.shapes.add_picture(os.path.join(OUTDIR, \"margins_udan_comparison.png\"), Inches(0.5), Inches(1.25), width=Inches(9))\n",
    "    # Slide 3: Vulnerable routes (top 6)\n",
    "    s3 = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "    s3.shapes.title.text = \"Slide 3 — Vulnerable routes (post-shock)\"\n",
    "    vuln = df_shock.sort_values(\"margin_post_shock\").head(6)\n",
    "    tx = s3.shapes.add_textbox(Inches(0.5), Inches(1.0), Inches(9), Inches(4))\n",
    "    tf = tx.text_frame\n",
    "    for _, row in vuln.iterrows():\n",
    "        tf.add_paragraph().text = f\"{row['src_iata']}-{row['dst_iata']} | dist {row['distance_km']} km | post_shock margin {row['margin_post_shock']:.0f} INR\"\n",
    "    # Slide 4: UDAN impact & recommendation\n",
    "    s4 = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    s4.shapes.title.text = \"Slide 4 — UDAN impact & Recommendation\"\n",
    "    s4.placeholders[1].text = (\n",
    "        \"Option B (UDAN) can stabilize a subset of fragile regional routes short-term.\\n\"\n",
    "        f\"It saves {num_saved_by_udan} routes from being loss-making under a +{ASSUMPTIONS['fuel_shock_pct']*100:.0f}% fuel shock.\\n\"\n",
    "        \"Recommendation: Use UDAN selectively as downside insurance; prioritize network optimization on core routes.\"\n",
    "    )\n",
    "    # Slide 5: KPIs & fallback plan\n",
    "    s5 = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "    s5.shapes.title.text = \"Slide 5 — KPIs & Exit Triggers\"\n",
    "    s5.placeholders[1].text = (\n",
    "        \"KPIs: Route-level EBITDA margin, CASK, Cash burn rate.\\n\"\n",
    "        \"Triggers: Exit route if margin < threshold for 2 consecutive quarters.\\n\"\n",
    "        \"Begin structural redesign planning (fleet mix) as Phase 2; do not lock entire fleet into UDAN.\"\n",
    "    )\n",
    "    pptx_path = os.path.join(OUTDIR, \"fuel_shock_udan_deck.pptx\")\n",
    "    prs.save(pptx_path)\n",
    "    print(\"  - PPTX generated: outputs/fuel_shock_udan_deck.pptx\")\n",
    "except Exception as e:\n",
    "    print(\"  - PPTX generation skipped (python-pptx may be missing or failed):\", e)\n",
    "\n",
    "print(\"\\nDONE. Outputs are in the 'outputs' folder:\")\n",
    "print(\" - outputs/atf_time_series.csv\")\n",
    "print(\" - outputs/atf_timeseries.png\")\n",
    "print(\" - outputs/route_economics_base.csv\")\n",
    "print(\" - outputs/route_economics_postshock_udan.csv\")\n",
    "print(\" - outputs/routes_saved_by_udan_top20.csv\")\n",
    "print(\" - outputs/summary_metrics_udan.txt\")\n",
    "print(\" - outputs/margins_udan_comparison.png\")\n",
    "print(\" - optional: outputs/fuel_shock_udan_deck.pptx (if python-pptx installed)\")\n",
    "\n",
    "# End of script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5f658d-eb4d-41b0-a782-df521d73b8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas_datareader in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: pulp in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy matplotlib requests pandas_datareader beautifulsoup4 lxml pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd68e82-b213-49a0-b560-26abb37c1c0f",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE. Outputs:\n",
      " - outputs/sensitivity_results.csv\n",
      " - outputs/routes_saved_vs_budget.png\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# MBB-STYLE ATF SHOCK + UDAN OPTIMIZATION (A+B+C+D)\n",
    "# ==========================================================\n",
    "\n",
    "import os, io, math, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pandas_datareader.data import DataReader\n",
    "from bs4 import BeautifulSoup\n",
    "import pulp\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "OUTDIR = \"outputs\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "ASSUMPTIONS = {\n",
    "    \"avg_seats\": 78,\n",
    "    \"load_factor\": 0.72,\n",
    "    \"avg_fare\": 3000,\n",
    "    \"ancillary\": 400,\n",
    "    \"fixed_cost\": 250000,\n",
    "    \"fuel_liters_km_seat\": 0.03,\n",
    "    \"usd_to_inr\": 82,\n",
    "    \"flights_per_month\": 60,\n",
    "    \"horizon_months\": 12,\n",
    "    \"fuel_shocks\": [0.15, 0.25, 0.40],\n",
    "    \"budgets\": [5e6, 10e6, 20e6, 40e6],  # INR\n",
    "    \"openflights_airports\": \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\",\n",
    "    \"openflights_routes\": \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat\",\n",
    "    \"fred_series\": \"DJFUELUSGULF\"\n",
    "}\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    p1, p2 = math.radians(lat1), math.radians(lat2)\n",
    "    dp = math.radians(lat2 - lat1)\n",
    "    dl = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dp/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dl/2)**2\n",
    "    return 2 * R * math.asin(math.sqrt(a))\n",
    "\n",
    "# ---------------- ROUTES ----------------\n",
    "airports = pd.read_csv(ASSUMPTIONS[\"openflights_airports\"], header=None)\n",
    "routes = pd.read_csv(ASSUMPTIONS[\"openflights_routes\"], header=None)\n",
    "\n",
    "airports.columns = [\"id\",\"name\",\"city\",\"country\",\"iata\",\"icao\",\"lat\",\"lon\",\"alt\",\"tz\",\"dst\",\"tzdb\",\"type\",\"src\"]\n",
    "routes.columns = [\"airline\",\"airline_id\",\"src\",\"src_id\",\"dst\",\"dst_id\",\"codeshare\",\"stops\",\"equip\"]\n",
    "\n",
    "airports[\"lat\"] = pd.to_numeric(airports[\"lat\"], errors=\"coerce\")\n",
    "airports[\"lon\"] = pd.to_numeric(airports[\"lon\"], errors=\"coerce\")\n",
    "airports[\"id\"] = pd.to_numeric(airports[\"id\"], errors=\"coerce\")\n",
    "routes[\"src_id\"] = pd.to_numeric(routes[\"src_id\"], errors=\"coerce\")\n",
    "routes[\"dst_id\"] = pd.to_numeric(routes[\"dst_id\"], errors=\"coerce\")\n",
    "\n",
    "india = airports[airports[\"country\"].str.lower() == \"india\"]\n",
    "ids = set(india[\"id\"].dropna().astype(int))\n",
    "routes = routes[routes[\"src_id\"].isin(ids) & routes[\"dst_id\"].isin(ids)]\n",
    "\n",
    "idx = india.set_index(\"id\")[[\"iata\",\"city\",\"lat\",\"lon\"]]\n",
    "\n",
    "rows = []\n",
    "for _, r in routes.iterrows():\n",
    "    try:\n",
    "        s, d = idx.loc[r[\"src_id\"]], idx.loc[r[\"dst_id\"]]\n",
    "        dist = haversine(s.lat, s.lon, d.lat, d.lon)\n",
    "        rows.append({\"route\": f\"{s.iata}-{d.iata}\", \"distance\": dist})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_routes = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# ---------------- ATF (REAL) ----------------\n",
    "try:\n",
    "    end = datetime.today()\n",
    "    start = datetime(end.year - 5, end.month, end.day)\n",
    "    fuel = DataReader(ASSUMPTIONS[\"fred_series\"], \"fred\", start, end).dropna()\n",
    "    fuel[\"inr_l\"] = (fuel.iloc[:,0] / 3.78541) * ASSUMPTIONS[\"usd_to_inr\"]\n",
    "    atf_price = fuel[\"inr_l\"].iloc[-1]\n",
    "except:\n",
    "    atf_price = 120  # fallback\n",
    "\n",
    "# ---------------- BASE ECONOMICS ----------------\n",
    "df = df_routes.copy()\n",
    "df[\"pax\"] = ASSUMPTIONS[\"avg_seats\"] * ASSUMPTIONS[\"load_factor\"]\n",
    "df[\"revenue\"] = df[\"pax\"] * (ASSUMPTIONS[\"avg_fare\"] + ASSUMPTIONS[\"ancillary\"])\n",
    "df[\"fuel_l\"] = df[\"distance\"] * ASSUMPTIONS[\"avg_seats\"] * ASSUMPTIONS[\"fuel_liters_km_seat\"]\n",
    "df[\"fuel_cost\"] = df[\"fuel_l\"] * atf_price\n",
    "df[\"cost\"] = df[\"fuel_cost\"] + ASSUMPTIONS[\"fixed_cost\"]\n",
    "df[\"margin\"] = df[\"revenue\"] - df[\"cost\"]\n",
    "\n",
    "# SOCIAL WEIGHTS (C)\n",
    "df[\"weight\"] = 1 + (df[\"distance\"] / df[\"distance\"].max())  # proxy\n",
    "\n",
    "# ---------------- OPTIMIZATION ENGINE ----------------\n",
    "results = []\n",
    "\n",
    "for shock in ASSUMPTIONS[\"fuel_shocks\"]:\n",
    "    df[\"margin_shock\"] = df[\"revenue\"] - (df[\"fuel_l\"] * atf_price * (1+shock) + ASSUMPTIONS[\"fixed_cost\"])\n",
    "    df[\"loss\"] = df[\"margin_shock\"].clip(upper=0).abs()\n",
    "\n",
    "    annual_loss = df[\"loss\"] * ASSUMPTIONS[\"flights_per_month\"] * ASSUMPTIONS[\"horizon_months\"]\n",
    "\n",
    "    for budget in ASSUMPTIONS[\"budgets\"]:\n",
    "        prob = pulp.LpProblem(\"UDAN\", pulp.LpMaximize)\n",
    "        x = pulp.LpVariable.dicts(\"subsidy\", df.index, lowBound=0)\n",
    "\n",
    "        # A+B+C Objective: weighted margin preserved\n",
    "        prob += pulp.lpSum(df.loc[i,\"weight\"] * x[i] for i in df.index)\n",
    "\n",
    "        # Budget constraint\n",
    "        prob += pulp.lpSum(x[i] for i in df.index) <= budget\n",
    "\n",
    "        # Cannot subsidize more than loss\n",
    "        for i in df.index:\n",
    "            prob += x[i] <= annual_loss[i]\n",
    "\n",
    "        prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "\n",
    "        total_saved = sum(pulp.value(x[i]) for i in df.index)\n",
    "        routes_saved = sum(1 for i in df.index if pulp.value(x[i]) >= annual_loss[i] * 0.95)\n",
    "\n",
    "        results.append({\n",
    "            \"fuel_shock\": shock,\n",
    "            \"budget_mn\": budget/1e6,\n",
    "            \"routes_saved\": routes_saved,\n",
    "            \"margin_saved_mn\": total_saved/1e6\n",
    "        })\n",
    "\n",
    "# ---------------- RESULTS ----------------\n",
    "res = pd.DataFrame(results)\n",
    "res.to_csv(f\"{OUTDIR}/sensitivity_results.csv\", index=False)\n",
    "\n",
    "# ---------------- PLOTS ----------------\n",
    "for shock in ASSUMPTIONS[\"fuel_shocks\"]:\n",
    "    subset = res[res[\"fuel_shock\"] == shock]\n",
    "    plt.plot(subset[\"budget_mn\"], subset[\"routes_saved\"], marker=\"o\", label=f\"{int(shock*100)}% ATF shock\")\n",
    "\n",
    "plt.xlabel(\"Annual Subsidy Budget (₹ Mn)\")\n",
    "plt.ylabel(\"Routes Fully Saved\")\n",
    "plt.title(\"UDAN Impact Sensitivity — MBB Style\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTDIR}/routes_saved_vs_budget.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"DONE. Outputs:\")\n",
    "print(\" - outputs/sensitivity_results.csv\")\n",
    "print(\" - outputs/routes_saved_vs_budget.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ff2d2c-b833-4508-8b7b-d0ce8290791c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas_datareader in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: pulp in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anklesh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy matplotlib requests pandas_datareader beautifulsoup4 lxml pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18be94a-68fa-4209-8c6e-eeb0c1302e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE.\n",
      "Outputs:\n",
      " - outputs/policy_sensitivity.csv\n",
      " - outputs/policy_frontier.png\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# MBB AIRLINE FUEL CRISIS ENGINE\n",
    "# Pricing + Subsidy + Exit + Social Weights + Sensitivity\n",
    "# ==========================================================\n",
    "\n",
    "import os, io, math, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pandas_datareader.data import DataReader\n",
    "from bs4 import BeautifulSoup\n",
    "import pulp\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "OUTDIR = \"outputs\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "CFG = {\n",
    "    \"avg_seats\": 78,\n",
    "    \"base_load_factor\": 0.72,\n",
    "    \"avg_fare\": 3000,\n",
    "    \"ancillary\": 400,\n",
    "    \"fixed_cost\": 250000,\n",
    "    \"fuel_liters_km_seat\": 0.03,\n",
    "    \"usd_to_inr\": 82,\n",
    "\n",
    "    \"price_increase\": 0.06,\n",
    "    \"elasticity\": -1.1,\n",
    "\n",
    "    \"flights_per_month\": 60,\n",
    "    \"horizon_months\": 12,\n",
    "\n",
    "    \"fuel_shocks\": [0.15, 0.25, 0.40],\n",
    "    \"budgets\": [5e6, 10e6, 20e6, 40e6],\n",
    "\n",
    "    \"exit_loss_threshold_annual\": 2_000_000,  # ₹2M annual loss\n",
    "\n",
    "    \"fred_series\": \"DJFUELUSGULF\",\n",
    "    \"airports_url\": \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\",\n",
    "    \"routes_url\": \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat\",\n",
    "}\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    p1, p2 = math.radians(lat1), math.radians(lat2)\n",
    "    dp = math.radians(lat2 - lat1)\n",
    "    dl = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dp/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dl/2)**2\n",
    "    return 2 * R * math.asin(math.sqrt(a))\n",
    "\n",
    "# ---------------- ROUTE UNIVERSE ----------------\n",
    "airports = pd.read_csv(CFG[\"airports_url\"], header=None)\n",
    "routes = pd.read_csv(CFG[\"routes_url\"], header=None)\n",
    "\n",
    "airports.columns = [\"id\",\"name\",\"city\",\"country\",\"iata\",\"icao\",\"lat\",\"lon\",\"alt\",\"tz\",\"dst\",\"tzdb\",\"type\",\"src\"]\n",
    "routes.columns = [\"airline\",\"airline_id\",\"src\",\"src_id\",\"dst\",\"dst_id\",\"codeshare\",\"stops\",\"equip\"]\n",
    "\n",
    "airports[\"lat\"] = pd.to_numeric(airports[\"lat\"], errors=\"coerce\")\n",
    "airports[\"lon\"] = pd.to_numeric(airports[\"lon\"], errors=\"coerce\")\n",
    "airports[\"id\"] = pd.to_numeric(airports[\"id\"], errors=\"coerce\")\n",
    "routes[\"src_id\"] = pd.to_numeric(routes[\"src_id\"], errors=\"coerce\")\n",
    "routes[\"dst_id\"] = pd.to_numeric(routes[\"dst_id\"], errors=\"coerce\")\n",
    "\n",
    "india = airports[airports[\"country\"].str.lower() == \"india\"]\n",
    "ids = set(india[\"id\"].dropna().astype(int))\n",
    "routes = routes[routes[\"src_id\"].isin(ids) & routes[\"dst_id\"].isin(ids)]\n",
    "\n",
    "idx = india.set_index(\"id\")[[\"iata\",\"city\",\"lat\",\"lon\"]]\n",
    "\n",
    "rows = []\n",
    "for _, r in routes.iterrows():\n",
    "    try:\n",
    "        s, d = idx.loc[r[\"src_id\"]], idx.loc[r[\"dst_id\"]]\n",
    "        rows.append({\n",
    "            \"route\": f\"{s.iata}-{d.iata}\",\n",
    "            \"distance\": haversine(s.lat, s.lon, d.lat, d.lon)\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# ---------------- REAL ATF ----------------\n",
    "try:\n",
    "    end = datetime.today()\n",
    "    start = datetime(end.year - 5, end.month, end.day)\n",
    "    fuel = DataReader(CFG[\"fred_series\"], \"fred\", start, end).dropna()\n",
    "    atf = (fuel.iloc[-1,0] / 3.78541) * CFG[\"usd_to_inr\"]\n",
    "except:\n",
    "    atf = 120  # fallback INR/L\n",
    "\n",
    "# ---------------- BASE ECONOMICS ----------------\n",
    "df[\"pax\"] = CFG[\"avg_seats\"] * CFG[\"base_load_factor\"]\n",
    "df[\"revenue\"] = df[\"pax\"] * (CFG[\"avg_fare\"] + CFG[\"ancillary\"])\n",
    "df[\"fuel_l\"] = df[\"distance\"] * CFG[\"avg_seats\"] * CFG[\"fuel_liters_km_seat\"]\n",
    "df[\"fuel_cost\"] = df[\"fuel_l\"] * atf\n",
    "df[\"cost\"] = df[\"fuel_cost\"] + CFG[\"fixed_cost\"]\n",
    "df[\"margin_base\"] = df[\"revenue\"] - df[\"cost\"]\n",
    "\n",
    "# ---------------- SOCIAL WEIGHTS (REALISTIC PROXY) ----------------\n",
    "# Distance-weighted connectivity proxy (can be replaced with Census/GDP CSV)\n",
    "df[\"social_weight\"] = 1 + (df[\"distance\"] / df[\"distance\"].max())\n",
    "\n",
    "# ---------------- CORE ENGINE ----------------\n",
    "results = []\n",
    "route_decisions = []\n",
    "\n",
    "for shock in CFG[\"fuel_shocks\"]:\n",
    "    df[\"fuel_cost_shock\"] = df[\"fuel_l\"] * atf * (1 + shock)\n",
    "    df[\"cost_shock\"] = df[\"fuel_cost_shock\"] + CFG[\"fixed_cost\"]\n",
    "\n",
    "    # Pricing effect\n",
    "    df[\"fare_new\"] = CFG[\"avg_fare\"] * (1 + CFG[\"price_increase\"])\n",
    "    df[\"lf_new\"] = CFG[\"base_load_factor\"] * (1 + CFG[\"elasticity\"] * CFG[\"price_increase\"])\n",
    "    df[\"lf_new\"] = df[\"lf_new\"].clip(0.4, 0.95)\n",
    "\n",
    "    df[\"pax_new\"] = CFG[\"avg_seats\"] * df[\"lf_new\"]\n",
    "    df[\"revenue_priced\"] = df[\"pax_new\"] * (df[\"fare_new\"] + CFG[\"ancillary\"])\n",
    "    df[\"margin_priced\"] = df[\"revenue_priced\"] - df[\"cost_shock\"]\n",
    "\n",
    "    df[\"residual_loss\"] = df[\"margin_priced\"].clip(upper=0).abs()\n",
    "    df[\"annual_loss\"] = df[\"residual_loss\"] * CFG[\"flights_per_month\"] * CFG[\"horizon_months\"]\n",
    "\n",
    "    for budget in CFG[\"budgets\"]:\n",
    "        prob = pulp.LpProblem(\"UDAN_OPT\", pulp.LpMaximize)\n",
    "        x = pulp.LpVariable.dicts(\"subsidy\", df.index, lowBound=0)\n",
    "\n",
    "        prob += pulp.lpSum(df.loc[i,\"social_weight\"] * x[i] for i in df.index)\n",
    "        prob += pulp.lpSum(x[i] for i in df.index) <= budget\n",
    "\n",
    "        for i in df.index:\n",
    "            prob += x[i] <= df.loc[i,\"annual_loss\"]\n",
    "\n",
    "        prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "\n",
    "        saved = 0\n",
    "        exited = 0\n",
    "        for i in df.index:\n",
    "            subsidized = pulp.value(x[i])\n",
    "            if subsidized >= df.loc[i,\"annual_loss\"] * 0.95:\n",
    "                saved += 1\n",
    "            elif df.loc[i,\"annual_loss\"] > CFG[\"exit_loss_threshold_annual\"]:\n",
    "                exited += 1\n",
    "\n",
    "        results.append({\n",
    "            \"fuel_shock\": shock,\n",
    "            \"budget_mn\": budget/1e6,\n",
    "            \"routes_saved\": saved,\n",
    "            \"routes_exit\": exited\n",
    "        })\n",
    "\n",
    "res = pd.DataFrame(results)\n",
    "res.to_csv(f\"{OUTDIR}/policy_sensitivity.csv\", index=False)\n",
    "\n",
    "# ---------------- VISUAL ----------------\n",
    "for shock in CFG[\"fuel_shocks\"]:\n",
    "    sub = res[res[\"fuel_shock\"] == shock]\n",
    "    plt.plot(sub[\"budget_mn\"], sub[\"routes_saved\"], marker=\"o\", label=f\"{int(shock*100)}% ATF\")\n",
    "\n",
    "plt.xlabel(\"Annual Subsidy Budget (₹ Mn)\")\n",
    "plt.ylabel(\"Routes Saved\")\n",
    "plt.title(\"Policy Frontier: Budget vs Routes Saved\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTDIR}/policy_frontier.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"DONE.\")\n",
    "print(\"Outputs:\")\n",
    "print(\" - outputs/policy_sensitivity.csv\")\n",
    "print(\" - outputs/policy_frontier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e106e2-7d19-46ae-996f-af0064633be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading route universe...\n",
      "Fetching ATF price (stable FRED fallback)...\n",
      "Running policy optimization...\n",
      "MODEL COMPLETE.\n",
      "Generated:\n",
      " - outputs/policy_results_final.csv\n",
      " - outputs/policy_frontier_final.png\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# MBB AIRLINE POLICY ENGINE — FINAL, HARDENED VERSION\n",
    "# Pricing + Frequency + Subsidy + Exit + Sensitivity\n",
    "# NO DASHBOARDS | NO BROKEN URL DEPENDENCIES\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pandas_datareader.data import DataReader\n",
    "import pulp\n",
    "\n",
    "# ================= CONFIG =================\n",
    "OUTDIR = \"outputs\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "CFG = {\n",
    "    # Fleet & demand\n",
    "    \"avg_seats\": 78,\n",
    "    \"base_lf\": 0.72,\n",
    "    \"avg_fare\": 3000,\n",
    "    \"ancillary\": 400,\n",
    "\n",
    "    # Costs\n",
    "    \"fixed_cost\": 250000,\n",
    "    \"fuel_liters_km_seat\": 0.03,\n",
    "    \"usd_to_inr\": 82,\n",
    "\n",
    "    # Pricing lever\n",
    "    \"price_increase\": 0.06,\n",
    "    \"elasticity\": -1.1,\n",
    "\n",
    "    # Frequency lever\n",
    "    \"freq_reduction\": 0.20,        # 20% cut\n",
    "    \"freq_demand_penalty\": 0.08,   # demand impact\n",
    "\n",
    "    # Planning\n",
    "    \"flights_per_month\": 60,\n",
    "    \"horizon_months\": 12,\n",
    "\n",
    "    # Policy space\n",
    "    \"fuel_shocks\": [0.15, 0.25, 0.40],\n",
    "    \"budgets\": [5e6, 10e6, 20e6, 40e6],\n",
    "    \"exit_loss_threshold\": 2_000_000,  # INR / year\n",
    "\n",
    "    # Stable data sources\n",
    "    \"fred_series\": \"DJFUELUSGULF\",\n",
    "    \"airports_url\": \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\",\n",
    "    \"routes_url\": \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat\",\n",
    "}\n",
    "\n",
    "# ================= HELPERS =================\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    p1, p2 = math.radians(lat1), math.radians(lat2)\n",
    "    dp = math.radians(lat2 - lat1)\n",
    "    dl = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dp/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dl/2)**2\n",
    "    return 2 * R * math.asin(math.sqrt(a))\n",
    "\n",
    "# ================= ROUTE UNIVERSE =================\n",
    "print(\"Loading route universe...\")\n",
    "\n",
    "airports = pd.read_csv(CFG[\"airports_url\"], header=None)\n",
    "routes = pd.read_csv(CFG[\"routes_url\"], header=None)\n",
    "\n",
    "airports.columns = [\"id\",\"name\",\"city\",\"country\",\"iata\",\"icao\",\"lat\",\"lon\",\"alt\",\"tz\",\"dst\",\"tzdb\",\"type\",\"src\"]\n",
    "routes.columns = [\"airline\",\"airline_id\",\"src\",\"src_id\",\"dst\",\"dst_id\",\"codeshare\",\"stops\",\"equip\"]\n",
    "\n",
    "airports[\"lat\"] = pd.to_numeric(airports[\"lat\"], errors=\"coerce\")\n",
    "airports[\"lon\"] = pd.to_numeric(airports[\"lon\"], errors=\"coerce\")\n",
    "airports[\"id\"] = pd.to_numeric(airports[\"id\"], errors=\"coerce\")\n",
    "routes[\"src_id\"] = pd.to_numeric(routes[\"src_id\"], errors=\"coerce\")\n",
    "routes[\"dst_id\"] = pd.to_numeric(routes[\"dst_id\"], errors=\"coerce\")\n",
    "\n",
    "india = airports[airports[\"country\"].str.lower() == \"india\"]\n",
    "ids = set(india[\"id\"].dropna().astype(int))\n",
    "routes = routes[routes[\"src_id\"].isin(ids) & routes[\"dst_id\"].isin(ids)]\n",
    "\n",
    "idx = india.set_index(\"id\")[[\"iata\",\"city\",\"lat\",\"lon\"]]\n",
    "\n",
    "rows = []\n",
    "for _, r in routes.iterrows():\n",
    "    try:\n",
    "        s, d = idx.loc[r[\"src_id\"]], idx.loc[r[\"dst_id\"]]\n",
    "        rows.append({\n",
    "            \"route\": f\"{s.iata}-{d.iata}\",\n",
    "            \"distance\": haversine(s.lat, s.lon, d.lat, d.lon)\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# ================= ATF PRICE =================\n",
    "print(\"Fetching ATF price (stable FRED fallback)...\")\n",
    "\n",
    "try:\n",
    "    end = datetime.today()\n",
    "    start = datetime(end.year - 5, end.month, end.day)\n",
    "    fuel = DataReader(CFG[\"fred_series\"], \"fred\", start, end).dropna()\n",
    "    atf = (fuel.iloc[-1,0] / 3.78541) * CFG[\"usd_to_inr\"]\n",
    "except:\n",
    "    atf = 120  # conservative fallback\n",
    "\n",
    "# ================= SOCIAL WEIGHTS =================\n",
    "# Robust, dependency-free proxy\n",
    "df[\"social_weight\"] = 1 + (df[\"distance\"] / df[\"distance\"].max())\n",
    "\n",
    "# ================= BASE ECONOMICS =================\n",
    "df[\"pax\"] = CFG[\"avg_seats\"] * CFG[\"base_lf\"]\n",
    "df[\"revenue\"] = df[\"pax\"] * (CFG[\"avg_fare\"] + CFG[\"ancillary\"])\n",
    "df[\"fuel_l\"] = df[\"distance\"] * CFG[\"avg_seats\"] * CFG[\"fuel_liters_km_seat\"]\n",
    "df[\"fuel_cost\"] = df[\"fuel_l\"] * atf\n",
    "df[\"cost\"] = df[\"fuel_cost\"] + CFG[\"fixed_cost\"]\n",
    "df[\"margin_base\"] = df[\"revenue\"] - df[\"cost\"]\n",
    "\n",
    "# ================= CORE ENGINE =================\n",
    "print(\"Running policy optimization...\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for shock in CFG[\"fuel_shocks\"]:\n",
    "    df[\"fuel_cost_shock\"] = df[\"fuel_l\"] * atf * (1 + shock)\n",
    "\n",
    "    # Pricing\n",
    "    df[\"fare_new\"] = CFG[\"avg_fare\"] * (1 + CFG[\"price_increase\"])\n",
    "    df[\"lf_priced\"] = CFG[\"base_lf\"] * (1 + CFG[\"elasticity\"] * CFG[\"price_increase\"])\n",
    "\n",
    "    # Frequency rationalisation\n",
    "    df[\"lf_final\"] = (df[\"lf_priced\"] * (1 - CFG[\"freq_demand_penalty\"])).clip(0.4, 0.95)\n",
    "\n",
    "    df[\"pax_final\"] = CFG[\"avg_seats\"] * df[\"lf_final\"]\n",
    "    df[\"revenue_final\"] = df[\"pax_final\"] * (df[\"fare_new\"] + CFG[\"ancillary\"])\n",
    "\n",
    "    df[\"cost_final\"] = (\n",
    "        df[\"fuel_cost_shock\"] * (1 - CFG[\"freq_reduction\"]) +\n",
    "        CFG[\"fixed_cost\"] * (1 - CFG[\"freq_reduction\"])\n",
    "    )\n",
    "\n",
    "    df[\"margin_final\"] = df[\"revenue_final\"] - df[\"cost_final\"]\n",
    "    df[\"annual_loss\"] = df[\"margin_final\"].clip(upper=0).abs() * CFG[\"flights_per_month\"] * CFG[\"horizon_months\"]\n",
    "\n",
    "    for budget in CFG[\"budgets\"]:\n",
    "        prob = pulp.LpProblem(\"POLICY\", pulp.LpMaximize)\n",
    "        x = pulp.LpVariable.dicts(\"subsidy\", df.index, lowBound=0)\n",
    "\n",
    "        # Objective: maximize weighted impact\n",
    "        prob += pulp.lpSum(df.loc[i,\"social_weight\"] * x[i] for i in df.index)\n",
    "\n",
    "        # Budget\n",
    "        prob += pulp.lpSum(x[i] for i in df.index) <= budget\n",
    "\n",
    "        # Cannot subsidize beyond loss\n",
    "        for i in df.index:\n",
    "            prob += x[i] <= df.loc[i,\"annual_loss\"]\n",
    "\n",
    "        prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "\n",
    "        saved = sum(\n",
    "            1 for i in df.index\n",
    "            if pulp.value(x[i]) >= df.loc[i,\"annual_loss\"] * 0.95\n",
    "        )\n",
    "\n",
    "        exited = sum(\n",
    "            1 for i in df.index\n",
    "            if df.loc[i,\"annual_loss\"] > CFG[\"exit_loss_threshold\"]\n",
    "            and pulp.value(x[i]) < df.loc[i,\"annual_loss\"] * 0.5\n",
    "        )\n",
    "\n",
    "        records.append({\n",
    "            \"fuel_shock\": shock,\n",
    "            \"budget_mn\": budget / 1e6,\n",
    "            \"routes_saved\": saved,\n",
    "            \"routes_exit\": exited\n",
    "        })\n",
    "\n",
    "# ================= OUTPUTS =================\n",
    "res = pd.DataFrame(records)\n",
    "res.to_csv(f\"{OUTDIR}/policy_results_final.csv\", index=False)\n",
    "\n",
    "for shock in CFG[\"fuel_shocks\"]:\n",
    "    s = res[res[\"fuel_shock\"] == shock]\n",
    "    plt.plot(s[\"budget_mn\"], s[\"routes_saved\"], marker=\"o\", label=f\"{int(shock*100)}% ATF\")\n",
    "\n",
    "plt.xlabel(\"Annual Subsidy Budget (₹ Mn)\")\n",
    "plt.ylabel(\"Routes Saved\")\n",
    "plt.title(\"Policy Frontier: Budget vs Routes Saved\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTDIR}/policy_frontier_final.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"MODEL COMPLETE.\")\n",
    "print(\"Generated:\")\n",
    "print(\" - outputs/policy_results_final.csv\")\n",
    "print(\" - outputs/policy_frontier_final.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb8e38-aa21-44df-bb57-b12e59280788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "panel-cell-order": [
   "8cd68e82-b213-49a0-b560-26abb37c1c0f"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
